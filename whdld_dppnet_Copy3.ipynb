{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajesh0305/M_Tech_Project/blob/main/whdld_dppnet_Copy3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8551f4dc",
      "metadata": {
        "id": "8551f4dc"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4c27cc",
      "metadata": {
        "id": "fc4c27cc",
        "outputId": "f6807e81-bb1e-4234-d7aa-e1579f0c791a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d12047",
      "metadata": {
        "id": "b4d12047"
      },
      "outputs": [],
      "source": [
        "color_dict = {\n",
        "    0: [128, 128, 128],     # gray = bare soil\n",
        "    1: [255, 0, 0],         # red = building\n",
        "    2: [192, 192, 0],       # olive = pavement\n",
        "    3: [255, 255, 0],       # yellow = road\n",
        "    4: [0, 255, 0],         # green = vegetation\n",
        "    5: [0, 0, 255],         # blue = water\n",
        "}\n",
        "\n",
        "def rgb_to_onehot(rgb_arr,color_dict=color_dict):\n",
        "    num_classes = len(color_dict)\n",
        "    shape = rgb_arr.shape[:2]+(num_classes,)\n",
        "    arr = np.zeros(shape,dtype = np.int8)\n",
        "    for i,cls in enumerate(color_dict):\n",
        "        arr[:,:,i] = np.all(rgb_arr.reshape((-1,3))==color_dict[i],axis=1).reshape(shape[:2])\n",
        "        arr = np.array(arr)\n",
        "    mask = np.argmax(arr,axis=-1)\n",
        "    return mask\n",
        "\n",
        "def onehot_to_rgb(onehot,color_dict = color_dict):\n",
        "    output = np.zeros(onehot.shape[:2]+(3,))\n",
        "    for k in color_dict.keys():\n",
        "        output[onehot==k]=color_dict[k]\n",
        "    return output\n",
        "\n",
        "def get_dataset(X_dir, y_dir):\n",
        "\n",
        "    num_samples = len(X_dir)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        X.append(plt.imread(X_dir[i]))\n",
        "        y.append(rgb_to_onehot(((plt.imread(y_dir[i]))[:,:,0:3])*255))\n",
        "\n",
        "    y = np.reshape(y, (-1, 256, 256, 1))\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f381f656",
      "metadata": {
        "id": "f381f656",
        "outputId": "64bda5bb-3fc3-4b40-b388-e72b04d7a8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3703 3703 414 414\n",
            "(3703, 256, 256, 3) (3703, 256, 256, 1) (414, 256, 256, 3) (414, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X_train = glob.glob(\"I:/WHDLD/train/X/*.jpg\")\n",
        "y_train = glob.glob(\"I:/WHDLD/train/y/*.png\")\n",
        "\n",
        "X_test = glob.glob(\"I:/WHDLD/test/X/*.jpg\")\n",
        "y_test = glob.glob(\"I:/WHDLD/test/y/*.png\")\n",
        "\n",
        "X_train.sort()\n",
        "y_train.sort()\n",
        "\n",
        "X_test.sort()\n",
        "y_test.sort()\n",
        "\n",
        "print(len(X_train), len(y_train), len(X_test), len(y_test))\n",
        "X_train, y_train = get_dataset(X_train, y_train)\n",
        "X_test, y_test = get_dataset(X_test, y_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e6e45f",
      "metadata": {
        "id": "43e6e45f"
      },
      "outputs": [],
      "source": [
        "np.save('I:/WHDLD/X_train.npy',X_train)\n",
        "np.save('I:/WHDLD/y_train.npy',y_train)\n",
        "np.save('I:/WHDLD/X_test.npy',X_test)\n",
        "np.save('I:/WHDLD/y_test.npy',y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384f3176",
      "metadata": {
        "id": "384f3176"
      },
      "outputs": [],
      "source": [
        "X_train = np.load('I:/WHDLD/X_train.npy')\n",
        "y_train = np.load('I:/WHDLD/y_train.npy')\n",
        "X_test = np.load('I:/WHDLD/X_test.npy')\n",
        "y_test = np.load('I:/WHDLD/y_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a626a82",
      "metadata": {
        "id": "0a626a82"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.backend import int_shape\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D,Conv2DTranspose, Conv3D, MaxPooling2D, MaxPooling3D, UpSampling2D, Add, BatchNormalization, Input, Activation, Lambda, Concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "def residual_separable(inp, n_filters, dropout=0.3, dilation=1, l2=None, name=\"down\"):\n",
        "    x = tf.keras.layers.SeparableConv2D(n_filters, (3, 3), strides=1, padding='same', activation=None,\n",
        "                        dilation_rate=dilation, use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform',\n",
        "                        pointwise_regularizer=regularizers.l2(0.00004))(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=dropout)(x)\n",
        "    if inp.shape[3] == x.shape[3]:\n",
        "        x = Add()([x, inp])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_separable_multi(inp, n_filters, dropout=0.3, dilation=1, l2=None, name=\"down\"):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1, padding='same', use_bias=False)(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x2 = tf.keras.layers.DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1, dilation_rate= (dilation, dilation), padding='same', use_bias=False)(inp)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "    x2 = Activation('relu')(x2)\n",
        "\n",
        "    x +=x2\n",
        "\n",
        "    x = Conv2D(n_filters, 1, strides=1, padding='same', activation=None,\n",
        "                         dilation_rate=1, use_bias=False, kernel_regularizer=regularizers.l2(0.00004))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Dropout(rate=dropout)(x)\n",
        "\n",
        "    if inp.shape[3] == x.shape[3]:\n",
        "        x = Add()([x, inp])\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def encoder_module(inp, n_filters, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\n",
        "    x = residual_separable(inp, n_filters, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n",
        "    x = residual_separable(x, n_filters, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n",
        "    return x\n",
        "\n",
        "def encoder_module_multi(inp, n_filters, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\n",
        "    x = residual_separable_multi(inp, n_filters, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n",
        "    x = residual_separable_multi(x, n_filters, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n",
        "    return x\n",
        "\n",
        "def upsample(x, n_filters, last=False, l2=None, name=\"down\"):\n",
        "    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same',use_bias=True,\n",
        "                                   activation=None,\n",
        "                                   kernel_regularizer=regularizers.l2(0.00004))(x)\n",
        "    if not last:\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def downsample(inp, n_filters_in, n_filters_out, bn=False, use_relu=False, l2=None, name=\"down\"):\n",
        "\n",
        "    if n_filters_in < n_filters_out:\n",
        "        filters_conv = n_filters_out - n_filters_in\n",
        "    else:\n",
        "        filters_conv = n_filters_out\n",
        "\n",
        "    x = Conv2D(filters_conv, 3, strides=2, padding='same', activation=None,\n",
        "                         dilation_rate=1, use_bias=False, kernel_regularizer=regularizers.l2(0.00004))(inp)\n",
        "\n",
        "    if n_filters_in < n_filters_out:\n",
        "        y =  MaxPooling2D(pool_size=(2, 2), strides=(2,2))(inp)\n",
        "        x =  concatenate([x,y], axis = -1)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def DPP(x,f):\n",
        "  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), strides = 2, padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), strides = 4, padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x1)\n",
        "  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x2)\n",
        "  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same', activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x3)\n",
        "  x1 = Conv2D(f,(1,1))(x1)\n",
        "  x2 = Conv2DTranspose(f, 3, strides=2, padding='same',use_bias=True, activation='relu')(x2)\n",
        "  x3 = Conv2DTranspose(f, 3, strides=4, padding='same',use_bias=True, activation='relu')(x3)\n",
        "  x = concatenate([x3,x2,x1], axis=3)\n",
        "  x1 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (1,1), activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x2 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (2,2), activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x3 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (4,4), activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x4 = tf.keras.layers.SeparableConv2D(f, (3, 3), padding='same',dilation_rate = (8,8), activation='relu',\n",
        "                                       use_bias=False, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform')(x)\n",
        "  x = concatenate([x1,x2,x3,x4], axis=3)\n",
        "  x = Conv2D(f,(1,1))(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a923e1",
      "metadata": {
        "id": "58a923e1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.backend import int_shape\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "def feature_extractor(x,f,dropout=0.25, dilation=[1,1,1,1], l2=None, name=\"down\"):\n",
        "  x1_1 = residual_separable_multi(x, f, dropout=dropout, dilation=1, l2=l2, name=name)\n",
        "  x1_2 = residual_separable_multi(x, f//4, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\n",
        "  x2 = concatenate([x,x1_2])\n",
        "  x2_1 = residual_separable_multi(x2, f, dropout=dropout, dilation=1, l2=l2, name=name)\n",
        "  x2_2 = residual_separable_multi(x2_1, f//4, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\n",
        "  x3 = concatenate([x,x1_2,x2_2])\n",
        "  x3_1 = residual_separable_multi(x3, f, dropout=dropout, dilation=1, l2=l2, name=name)\n",
        "  x3_2 = residual_separable_multi(x3_1, f//4, dropout=dropout, dilation=dilation[2], l2=l2, name=name)\n",
        "  x4 = concatenate([x,x1_2,x2_2,x3_2])\n",
        "  x4_1 = residual_separable_multi(x4, f, dropout=dropout, dilation=1, l2=l2, name=name)\n",
        "  x4_2 = residual_separable_multi(x4_1, f//4, dropout=dropout, dilation=dilation[3], l2=l2, name=name)\n",
        "  xout = concatenate([x,x1_2,x2_2,x3_2,x4_2])\n",
        "  return xout\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5711a62",
      "metadata": {
        "id": "b5711a62",
        "outputId": "1fbb6ad1-91f0-42e3-c5de-3c0efd1592f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 13) 351         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128, 128, 16) 0           conv2d[0][0]                     \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 16) 64          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 48)   6912        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 64)   4672        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 64, 64, 64)   0           dropout[0][0]                    \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 64)   4672        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 64, 64)   0           dropout_1[0][0]                  \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 64)   4672        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 64)   0           dropout_2[0][0]                  \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 64)   4672        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 64)   0           dropout_3[0][0]                  \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 64)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 64)   4672        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 64, 64, 64)   0           dropout_4[0][0]                  \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 64)   4672        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 64, 64, 64)   0           dropout_5[0][0]                  \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 64)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 64, 64, 64)   4672        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 64, 64, 64)   0           dropout_6[0][0]                  \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 64)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 64, 64, 64)   4672        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 64)   0           dropout_7[0][0]                  \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 64)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 64, 64, 64)   4672        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 64)   0           dropout_8[0][0]                  \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 64)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 64, 64, 64)   4672        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 64)   256         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 64, 64)   0           dropout_9[0][0]                  \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 64)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36864       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           conv2d_2[0][0]                   \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_2 (DepthwiseCo (None, 32, 32, 128)  1152        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_3 (DepthwiseCo (None, 32, 32, 128)  1152        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 32, 32, 128)  0           activation_16[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   4096        tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 32)   0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 160)  0           activation_12[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_4 (DepthwiseCo (None, 32, 32, 160)  1440        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_5 (DepthwiseCo (None, 32, 32, 160)  1440        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 160)  640         depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 160)  640         depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 160)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 160)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 32, 32, 160)  0           activation_19[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  20480       tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 128)  0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_6 (DepthwiseCo (None, 32, 32, 128)  1152        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_7 (DepthwiseCo (None, 32, 32, 128)  1152        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 128)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 32, 32, 128)  0           activation_22[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4096        tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 32)   0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 192)  0           activation_12[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_8 (DepthwiseCo (None, 32, 32, 192)  1728        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_9 (DepthwiseCo (None, 32, 32, 192)  1728        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 192)  768         depthwise_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 192)  768         depthwise_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 192)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 192)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 32, 32, 192)  0           activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  24576       tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 128)  0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_10 (DepthwiseC (None, 32, 32, 128)  1152        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_11 (DepthwiseC (None, 32, 32, 128)  1152        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 128)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 128)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 32, 32, 128)  0           activation_28[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 32)   4096        tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 32)   0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 224)  0           activation_12[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_12 (DepthwiseC (None, 32, 32, 224)  2016        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_13 (DepthwiseC (None, 32, 32, 224)  2016        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 224)  896         depthwise_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 224)  896         depthwise_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 224)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 224)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 32, 32, 224)  0           activation_31[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  28672       tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 128)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_14 (DepthwiseC (None, 32, 32, 128)  1152        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_15 (DepthwiseC (None, 32, 32, 128)  1152        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 32, 32, 128)  0           activation_34[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   4096        tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 32)   0           dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 256)  0           activation_12[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_18 (DepthwiseC (None, 32, 32, 256)  2304        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_19 (DepthwiseC (None, 32, 32, 256)  2304        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 256)  1024        depthwise_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 256)  1024        depthwise_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 256)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 256)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 32, 32, 256)  0           activation_40[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 32)   8192        tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 32)   0           dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 288)  0           concatenate_6[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_20 (DepthwiseC (None, 32, 32, 288)  2592        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_21 (DepthwiseC (None, 32, 32, 288)  2592        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 288)  1152        depthwise_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 288)  1152        depthwise_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 288)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 288)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 32, 32, 288)  0           activation_43[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 128)  36864       tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 128)  512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 128)  0           dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_22 (DepthwiseC (None, 32, 32, 128)  1152        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_23 (DepthwiseC (None, 32, 32, 128)  1152        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 128)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 128)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 32, 32, 128)  0           activation_46[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 32)   4096        tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 32)   0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 320)  0           concatenate_6[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_24 (DepthwiseC (None, 32, 32, 320)  2880        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_25 (DepthwiseC (None, 32, 32, 320)  2880        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 320)  1280        depthwise_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 320)  1280        depthwise_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 320)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 320)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 32, 32, 320)  0           activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 128)  40960       tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 128)  0           dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_26 (DepthwiseC (None, 32, 32, 128)  1152        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_27 (DepthwiseC (None, 32, 32, 128)  1152        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 128)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 32, 32, 128)  0           activation_52[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 32)   4096        tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 32)   0           dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 352)  0           concatenate_6[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_28 (DepthwiseC (None, 32, 32, 352)  3168        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_29 (DepthwiseC (None, 32, 32, 352)  3168        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 352)  1408        depthwise_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 352)  1408        depthwise_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 352)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 352)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 32, 32, 352)  0           activation_55[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 128)  45056       tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 128)  0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_30 (DepthwiseC (None, 32, 32, 128)  1152        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_31 (DepthwiseC (None, 32, 32, 128)  1152        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 32, 32, 128)  512         depthwise_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 128)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 128)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 32, 32, 128)  0           activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 32)   4096        tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 32)   128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 32, 32, 32)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 32, 32, 32)   0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 384)  0           concatenate_6[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 64, 64, 64)   221248      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 64, 64, 64)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 64, 64, 64)   0           activation_61[0][0]              \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 16) 9232        tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 128, 128, 32) 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 32, 32, 32)   1312        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 64, 64, 32)   1312        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 128, 128, 32) 1312        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 32, 32, 32)   1312        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 64, 64, 32)   1312        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 128, 128, 32) 1312        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 9248        separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 9248        separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 128, 128, 32) 1056        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 128, 128, 96) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 128, 128, 32) 3936        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 128, 128, 32) 3936        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 128, 128, 32) 3936        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 128, 128, 32) 3936        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 128, 128, 128 0           separable_conv2d_16[0][0]        \n",
            "                                                                 separable_conv2d_17[0][0]        \n",
            "                                                                 separable_conv2d_18[0][0]        \n",
            "                                                                 separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 128, 128, 32) 4128        concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 128, 6)  198         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 256, 256, 6)  0           conv2d_21[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 679,925\n",
            "Trainable params: 665,301\n",
            "Non-trainable params: 14,624\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Activation, AveragePooling2D, DepthwiseConv2D, Conv2DTranspose\n",
        "import tensorflow.keras.backend as K\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Activation,Reshape, Add, Multiply, DepthwiseConv2D, BatchNormalization, Concatenate, Conv2D, Dense,Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Lambda,LeakyReLU, MaxPooling2D, Multiply, Permute, Reshape, UpSampling2D\n",
        "import collections\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def DPPNet(input_size,  n_classes, l2=None, upsampling=2):\n",
        "    inputs = Input(input_size)\n",
        "    d1 = downsample(inputs, 3, 16, l2=l2, name=\"d1\")\n",
        "    d2 = downsample(d1, n_filters_in=16, n_filters_out=64, l2=l2, name=\"d2\")\n",
        "    m1 = encoder_module(d2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres3\", dropout=0.0)\n",
        "    m2 = encoder_module(m1, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres4\", dropout=0.0)\n",
        "    m3 = encoder_module(m2, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres5\", dropout=0.0)\n",
        "    m4 = encoder_module(m3, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres6\", dropout=0.0)\n",
        "    m5 = encoder_module(m4, n_filters=64, dilation=[1, 1], l2=l2, name=\"fres7\", dropout=0.0)\n",
        "\n",
        "    d3 = downsample(m5,  n_filters_in=64, n_filters_out=128, l2=l2, name=\"d8\")\n",
        "    m6 = feature_extractor(d3,128,dropout=0.25, dilation=[2,4,8,16], l2=l2, name=\"fres9\")\n",
        "    m7 = feature_extractor(m6,128,dropout=0.25, dilation=[1,2,8,16], l2=l2, name=\"fres10\")\n",
        "    up1 = upsample(m7, n_filters=64, l2=l2, name=\"up11\")\n",
        "    x = up1+d2\n",
        "    up2 = upsample(x, n_filters=16, l2=l2, name=\"up16\", last = True)\n",
        "    x = concatenate([up2, d1], axis=3)\n",
        "    x = DPP(x,32)\n",
        "    x = Conv2D(6, (1, 1), activation='softmax')(x)\n",
        "    if upsampling > 1:\n",
        "      x = tf.keras.layers.experimental.preprocessing.Resizing(x.shape[1] * upsampling, x.shape[2] * upsampling)(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = DPPNet((256,256,3), 6)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff6b10b",
      "metadata": {
        "id": "bff6b10b",
        "outputId": "a1b7e50b-24a3-403c-ed16-5b97eb078e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "926/926 [==============================] - 150s 154ms/step - loss: 1.2120 - accuracy: 0.5720\n",
            "Epoch 2/100\n",
            "926/926 [==============================] - 145s 157ms/step - loss: 0.8274 - accuracy: 0.7033\n",
            "Epoch 3/100\n",
            "926/926 [==============================] - 145s 157ms/step - loss: 0.7146 - accuracy: 0.7446\n",
            "Epoch 4/100\n",
            "926/926 [==============================] - 145s 157ms/step - loss: 0.6880 - accuracy: 0.7541\n",
            "Epoch 5/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.6521 - accuracy: 0.7661\n",
            "Epoch 6/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.6267 - accuracy: 0.7753\n",
            "Epoch 7/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.6231 - accuracy: 0.7771\n",
            "Epoch 8/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.6083 - accuracy: 0.7826\n",
            "Epoch 9/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5868 - accuracy: 0.7907\n",
            "Epoch 10/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5866 - accuracy: 0.7905\n",
            "Epoch 11/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5779 - accuracy: 0.7935\n",
            "Epoch 12/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5753 - accuracy: 0.7944\n",
            "Epoch 13/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.5663 - accuracy: 0.7988\n",
            "Epoch 14/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5602 - accuracy: 0.8006\n",
            "Epoch 15/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5577 - accuracy: 0.8016\n",
            "Epoch 16/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5495 - accuracy: 0.8046\n",
            "Epoch 17/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5744 - accuracy: 0.7960\n",
            "Epoch 18/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5461 - accuracy: 0.8058\n",
            "Epoch 19/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5578 - accuracy: 0.8012\n",
            "Epoch 20/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5471 - accuracy: 0.8054\n",
            "Epoch 21/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5508 - accuracy: 0.8050\n",
            "Epoch 22/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.5442 - accuracy: 0.8068\n",
            "Epoch 23/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5478 - accuracy: 0.8066\n",
            "Epoch 24/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5382 - accuracy: 0.8091\n",
            "Epoch 25/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5325 - accuracy: 0.8109\n",
            "Epoch 26/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5486 - accuracy: 0.8064\n",
            "Epoch 27/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5359 - accuracy: 0.8106\n",
            "Epoch 28/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5366 - accuracy: 0.8101\n",
            "Epoch 29/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5285 - accuracy: 0.8127\n",
            "Epoch 30/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5367 - accuracy: 0.8106\n",
            "Epoch 31/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5327 - accuracy: 0.8125\n",
            "Epoch 32/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5230 - accuracy: 0.8154\n",
            "Epoch 33/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5208 - accuracy: 0.8165\n",
            "Epoch 34/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5183 - accuracy: 0.8175\n",
            "Epoch 35/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5370 - accuracy: 0.8105\n",
            "Epoch 36/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5281 - accuracy: 0.8133\n",
            "Epoch 37/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5264 - accuracy: 0.8148\n",
            "Epoch 38/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5338 - accuracy: 0.8124\n",
            "Epoch 39/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5275 - accuracy: 0.8135\n",
            "Epoch 40/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5174 - accuracy: 0.8172\n",
            "Epoch 41/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5245 - accuracy: 0.8143\n",
            "Epoch 42/100\n",
            "926/926 [==============================] - 144s 155ms/step - loss: 0.5173 - accuracy: 0.8174\n",
            "Epoch 43/100\n",
            "926/926 [==============================] - 144s 155ms/step - loss: 0.5131 - accuracy: 0.8195\n",
            "Epoch 44/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5145 - accuracy: 0.8199\n",
            "Epoch 45/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5149 - accuracy: 0.8181\n",
            "Epoch 46/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5169 - accuracy: 0.8181\n",
            "Epoch 47/100\n",
            "926/926 [==============================] - 144s 155ms/step - loss: 0.5159 - accuracy: 0.8185\n",
            "Epoch 48/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5084 - accuracy: 0.8209\n",
            "Epoch 49/100\n",
            "926/926 [==============================] - 144s 155ms/step - loss: 0.5110 - accuracy: 0.8201\n",
            "Epoch 50/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5218 - accuracy: 0.8178\n",
            "Epoch 51/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5155 - accuracy: 0.8180\n",
            "Epoch 52/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5192 - accuracy: 0.8182\n",
            "Epoch 53/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5123 - accuracy: 0.8196\n",
            "Epoch 54/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4996 - accuracy: 0.8252\n",
            "Epoch 55/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5154 - accuracy: 0.8187\n",
            "Epoch 56/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.5011 - accuracy: 0.8241\n",
            "Epoch 57/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5064 - accuracy: 0.8222\n",
            "Epoch 58/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5137 - accuracy: 0.8205\n",
            "Epoch 59/100\n",
            "926/926 [==============================] - 145s 157ms/step - loss: 0.5049 - accuracy: 0.8224\n",
            "Epoch 60/100\n",
            "926/926 [==============================] - 146s 158ms/step - loss: 0.4990 - accuracy: 0.8251\n",
            "Epoch 61/100\n",
            "926/926 [==============================] - 146s 158ms/step - loss: 0.5034 - accuracy: 0.8224\n",
            "Epoch 62/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.5073 - accuracy: 0.8226\n",
            "Epoch 63/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5005 - accuracy: 0.8239\n",
            "Epoch 64/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4981 - accuracy: 0.8255\n",
            "Epoch 65/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4959 - accuracy: 0.8253\n",
            "Epoch 66/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4990 - accuracy: 0.8249\n",
            "Epoch 67/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5088 - accuracy: 0.8219\n",
            "Epoch 68/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4977 - accuracy: 0.8258\n",
            "Epoch 69/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5068 - accuracy: 0.8221\n",
            "Epoch 70/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5024 - accuracy: 0.8243\n",
            "Epoch 71/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4997 - accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5071 - accuracy: 0.8220\n",
            "Epoch 73/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4971 - accuracy: 0.8263\n",
            "Epoch 74/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4988 - accuracy: 0.8254\n",
            "Epoch 75/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4996 - accuracy: 0.8247\n",
            "Epoch 76/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.5051 - accuracy: 0.8228\n",
            "Epoch 77/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4854 - accuracy: 0.8304\n",
            "Epoch 78/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5051 - accuracy: 0.8241\n",
            "Epoch 79/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4989 - accuracy: 0.8260\n",
            "Epoch 80/100\n",
            "926/926 [==============================] - 143s 154ms/step - loss: 0.4979 - accuracy: 0.8253\n",
            "Epoch 81/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4917 - accuracy: 0.8279\n",
            "Epoch 82/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4853 - accuracy: 0.8298\n",
            "Epoch 83/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4982 - accuracy: 0.8258\n",
            "Epoch 84/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4892 - accuracy: 0.8285\n",
            "Epoch 85/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4921 - accuracy: 0.8273\n",
            "Epoch 86/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4959 - accuracy: 0.8258\n",
            "Epoch 87/100\n",
            "926/926 [==============================] - 144s 155ms/step - loss: 0.4932 - accuracy: 0.8270\n",
            "Epoch 88/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.5067 - accuracy: 0.8228\n",
            "Epoch 89/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4899 - accuracy: 0.8286\n",
            "Epoch 90/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4892 - accuracy: 0.8283\n",
            "Epoch 91/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4965 - accuracy: 0.8260\n",
            "Epoch 92/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4847 - accuracy: 0.8300\n",
            "Epoch 93/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4924 - accuracy: 0.8277\n",
            "Epoch 94/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4975 - accuracy: 0.8260\n",
            "Epoch 95/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4829 - accuracy: 0.8310\n",
            "Epoch 96/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4940 - accuracy: 0.8280\n",
            "Epoch 97/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4933 - accuracy: 0.8272\n",
            "Epoch 98/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4955 - accuracy: 0.8259\n",
            "Epoch 99/100\n",
            "926/926 [==============================] - 145s 156ms/step - loss: 0.4899 - accuracy: 0.8282\n",
            "Epoch 100/100\n",
            "926/926 [==============================] - 144s 156ms/step - loss: 0.4844 - accuracy: 0.8303\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint('I:/WHDLD/mmini_whdld2.h5', monitor='loss', save_best_only=True)\n",
        "callback=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=4, callbacks = [model_checkpoint,callback] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bafc55",
      "metadata": {
        "id": "f9bafc55",
        "outputId": "4b1b0c90-014a-493d-f7ae-d8e9863a3d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.60920376\n",
            "0.8102886\n",
            "[[  643619    52248   257058    20334   165204    20437]\n",
            " [   24170  2839378   422343     9438   418638     3055]\n",
            " [  165119   643067  2412121   109308   621321     5991]\n",
            " [   26018    34357   239360   810385   134023     4072]\n",
            " [  224339   410782   683648    99986 11752730   146671]\n",
            " [    7927     5279     2872     2098   188068  3526440]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.56      0.57   1158900\n",
            "           1       0.71      0.76      0.74   3717022\n",
            "           2       0.60      0.61      0.60   3956927\n",
            "           3       0.77      0.65      0.70   1248215\n",
            "           4       0.88      0.88      0.88  13318156\n",
            "           5       0.95      0.94      0.95   3732684\n",
            "\n",
            "    accuracy                           0.81  27131904\n",
            "   macro avg       0.75      0.73      0.74  27131904\n",
            "weighted avg       0.81      0.81      0.81  27131904\n",
            "\n",
            "(414, 256, 256, 6) (414, 256, 256, 6)\n",
            "[0.6250159 0.7889846 0.6634375 0.7337095 0.9251705 0.9613425]\n",
            "0.7829434\n",
            "k 0.7273194460195977\n"
          ]
        }
      ],
      "source": [
        "model.save('I:/WHDLD/mminiwhdld2_model.h5')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from tensorflow.keras.metrics import MeanIoU, Accuracy\n",
        "\n",
        "meaniou = MeanIoU(6, name=None, dtype=None)\n",
        "meaniou.update_state(y_test, y_pred.argmax(axis=3))\n",
        "print(meaniou.result().numpy())\n",
        "meaniou.reset_states()\n",
        "\n",
        "acc = Accuracy()\n",
        "acc.update_state(y_test, y_pred.argmax(axis=3))\n",
        "print(acc.result().numpy())\n",
        "acc.reset_states()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test.ravel(), y_pred.argmax(axis=3).ravel())\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cr = classification_report(y_test.ravel(), y_pred.argmax(axis=3).ravel())\n",
        "print(cr)\n",
        "\n",
        "def get_dice(y_true, y_pred):\n",
        "\n",
        "    intersection = np.sum(y_true * y_pred, axis=(0, 1, 2))\n",
        "    union = np.sum(y_true**2, axis=(0, 1, 2)) + np.sum(y_pred**2, axis=(0, 1, 2))\n",
        "    dc = 2 * intersection / union\n",
        "    return dc\n",
        "\n",
        "print(y_pred.shape, tf.one_hot(y_test.reshape((-1, 256, 256)), depth=6).numpy().shape)\n",
        "\n",
        "dice_coeff = get_dice(tf.one_hot(y_test.reshape((-1,256, 256)), depth=6).numpy(), y_pred)\n",
        "print(dice_coeff)\n",
        "print(np.mean(dice_coeff))\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "k = cohen_kappa_score(y_test.ravel(), y_pred.argmax(axis=3).ravel())\n",
        "print(\"k\",k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4759e949",
      "metadata": {
        "id": "4759e949",
        "outputId": "5132b85f-721a-4751-a2a4-fa905e92a8e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10131931136"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
        "#https://github.com/tokusumi/keras-flops/blob/master/notebooks/flops_calculation_tfkeras.ipynb\n",
        "def get_flops(model, batch_size=None):\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "\n",
        "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
        "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
        "                                            run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops\n",
        "\n",
        "flops = get_flops(model,4)\n",
        "flops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bba2205",
      "metadata": {
        "id": "4bba2205"
      },
      "outputs": [],
      "source": [
        "i = 18\n",
        "test_img = model.predict(X_test[i,:,:,:].reshape((1, 256, 256, 3)))\n",
        "test_img = np.argmax(test_img, axis=3)\n",
        "\n",
        "# print(y_pred.shape, y_data[i, :, :].shape)\n",
        "\n",
        "test_img = onehot_to_rgb(test_img.reshape((256, 256)))\n",
        "#test_img_ = plt.imread(y_test[i])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(test_img/255)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow((onehot_to_rgb(y_test[i,:,:].reshape((256, 256))))/255)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(X_test[i, :, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22e84bb",
      "metadata": {
        "id": "c22e84bb",
        "outputId": "e9fcaa89-6ff6-4fa8-dfff-f42f6e84dc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8339028358459473\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "t10 = time.time()\n",
        "i = 51\n",
        "test_img = model.predict(X_test[i,:,:,:].reshape((1, 256, 256, 3)))\n",
        "#test_img = np.argmax(test_img, axis=3)\n",
        "t11 = time.time()\n",
        "time_forloop = t11 - t10\n",
        "print(time_forloop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261212e9",
      "metadata": {
        "id": "261212e9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}